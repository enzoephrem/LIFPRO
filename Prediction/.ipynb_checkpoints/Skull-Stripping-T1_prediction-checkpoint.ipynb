{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a2cdcbf-d030-4391-bdc8-4e6926bf418e",
   "metadata": {},
   "source": [
    "## Skull Stripping Prediction T1w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d07657f-23e4-459a-9af6-9e6457de2a65",
   "metadata": {},
   "source": [
    "### 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66bfb758-6d96-4762-b16c-566f2858413b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchio as tio\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import nibabel as nib\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c805863-f6e5-4882-90ba-f29345fd6611",
   "metadata": {},
   "source": [
    "Ignore : warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7525690-7954-4b8b-bb20-5d7ae43fecf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "__file__ = 'Skull-Stripping-T1_prediction.ipynb'\n",
    "BASE_DIR = Path(__file__).resolve().parent\n",
    "PARENT_DIR = BASE_DIR.parent\n",
    "lib_path = PARENT_DIR / \"Skull_Stripping\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ff0e221-52cb-4698-bbb4-7a360619de92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,str(lib_path)) #\n",
    "from lib.models import ResidualUNET3D\n",
    "from lib.runners import *\n",
    "from lib.data import *\n",
    "from lib.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591a45c0-390c-4608-ad74-c25f4aa2d450",
   "metadata": {},
   "source": [
    "### 2. Récupération de l'architechture du model T1w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed68148a-e4d8-40e3-a73e-4d5f786fb8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 32\n",
    "overlap_size = 16\n",
    "batch_size = 8\n",
    "\n",
    "device = \"cuda:0\"\n",
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9aa4ebf1-45a3-4da2-aef0-e89da97e95d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResidualUNET3D(in_channels=1, out_channels=1, optional_skip=True)\n",
    "model = torch.nn.DataParallel(model).to(device)\n",
    "model_name = \"ResidualUNET3D_Adam_10_3.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603a55ea-6779-4d95-a228-807dd60c36ec",
   "metadata": {},
   "source": [
    "### 2. Chargement du model T1w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68b6ad84-689b-4bad-ab9b-1f5cd2e5ed60",
   "metadata": {},
   "outputs": [],
   "source": [
    "__file__ = 'tumor_classifier.ipynb'\n",
    "BASE_DIR = Path(__file__).resolve().parent\n",
    "PARENT_BASE_DIR = BASE_DIR.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3ebf271-64ab-4a38-8279-2e831b7234a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model = PARENT_BASE_DIR / \"Skull_Stripping\" / \"models_skull-stripping\" / model_name\n",
    "path_model = str(path_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c37486b-e058-4130-921e-13fe3012de8a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ResidualUNET3D(\n",
       "    (conv1_1): Conv3d(1, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (norm1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (act1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (conv1_2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (conv1_short): Conv3d(1, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "    (residual_block1): ResidualBlock3D(\n",
       "      (norm1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (act1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (conv1): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (norm2): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (act2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (drop1): Dropout(p=0.2, inplace=False)\n",
       "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (norm3): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (act3): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "      (drop2): Dropout(p=0.1, inplace=False)\n",
       "      (conv3): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (norm4): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (act4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (conv_short): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (residual_block2): ResidualBlock3D(\n",
       "      (norm1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (act1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (conv1): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (norm2): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (act2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (drop1): Dropout(p=0.2, inplace=False)\n",
       "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (norm3): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (act3): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "      (drop2): Dropout(p=0.1, inplace=False)\n",
       "      (conv3): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (norm4): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (act4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (conv_short): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (residual_block3): ResidualBlock3D(\n",
       "      (norm1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (act1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (conv1): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "      (norm2): InstanceNorm3d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (act2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (drop1): Dropout(p=0.2, inplace=False)\n",
       "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (norm3): InstanceNorm3d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (act3): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "      (drop2): Dropout(p=0.1, inplace=False)\n",
       "      (conv3): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      (norm4): InstanceNorm3d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (act4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (conv_short): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (upscale_block1): Upscale3D(\n",
       "      (up): Upsample(scale_factor=2.0, mode=trilinear)\n",
       "      (residual): ResidualBlock3D(\n",
       "        (norm1): InstanceNorm3d(768, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (act1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (conv1): Conv3d(768, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (norm2): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (act2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (drop1): Dropout(p=0.2, inplace=False)\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (norm3): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (act3): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "        (drop2): Dropout(p=0.1, inplace=False)\n",
       "        (conv3): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (norm4): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (act4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (conv_short): Conv3d(768, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (upscale_block2): Upscale3D(\n",
       "      (up): Upsample(scale_factor=2.0, mode=trilinear)\n",
       "      (residual): ResidualBlock3D(\n",
       "        (norm1): InstanceNorm3d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (act1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (conv1): Conv3d(384, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (norm2): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (act2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (drop1): Dropout(p=0.2, inplace=False)\n",
       "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (norm3): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (act3): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "        (drop2): Dropout(p=0.1, inplace=False)\n",
       "        (conv3): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (norm4): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (act4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (conv_short): Conv3d(384, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (upscale_block3): Upscale3D(\n",
       "      (up): Upsample(scale_factor=2.0, mode=trilinear)\n",
       "      (residual): ResidualBlock3D(\n",
       "        (norm1): InstanceNorm3d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (act1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (conv1): Conv3d(192, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (norm2): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (act2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (drop1): Dropout(p=0.2, inplace=False)\n",
       "        (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (norm3): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (act3): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "        (drop2): Dropout(p=0.1, inplace=False)\n",
       "        (conv3): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (norm4): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        (act4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "        (conv_short): Conv3d(192, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (out): Conv3d(64, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "    (act2): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(path_model))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1eff8272-e7ab-427c-b4c1-235d6e75ff4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in the model: 35379008\n"
     ]
    }
   ],
   "source": [
    "total_parameters = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Number of parameters in the model: {total_parameters}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0da2668-36f3-41ce-9176-829fa1abb1cc",
   "metadata": {},
   "source": [
    "### 3. Recupération des IRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "360111d5-a078-4e93-9aaf-78af63757447",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_histogram_landmarks = PARENT_BASE_DIR / \"Skull_Stripping\" / \"ressources\" / \"NFBS_histogram_landmarks.npy\"\n",
    "path_histogram_landmarks = str(path_histogram_landmarks)\n",
    "\n",
    "valid_transforms = tio.Compose([\n",
    "        tio.ToCanonical(),\n",
    "        tio.Resample(1),\n",
    "        tio.HistogramStandardization({'mri': np.load(path_histogram_landmarks)}),\n",
    "        tio.ZNormalization(masking_method=tio.ZNormalization.mean)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3bd2e2f2-3b0f-448f-a04d-e0c117487202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des images\n",
    "path_mri_t1w = []\n",
    "for i in range (1,5):\n",
    "    path_mri_t1w.append(str(BASE_DIR / \"Skull-Stripping_prediction\" / \"T1\" / str(i) /\"image.nii.gz\"))\n",
    "          \n",
    "path_mri_t2w = []\n",
    "for i in range (1,5):\n",
    "    path_mri_t2w.append(str(BASE_DIR / \"Skull-Stripping_prediction\" / \"T2\" / str(i) /\"image.nii.gz\"))\n",
    "                        \n",
    "path_mri_infant = []\n",
    "for i in range (1,5):\n",
    "    path_mri_infant.append(str(BASE_DIR / \"Skull-Stripping_prediction\" / \"INFANT\" / str(i) /\"image.nii.gz\"))\n",
    "\n",
    "path_mri_flair = []\n",
    "for i in range (1,5):\n",
    "    path_mri_flair.append(str(BASE_DIR / \"Skull-Stripping_prediction\" / \"FLAIR\" / str(i) /\"image.nii.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef4e73ef-4903-4e20-8c2a-16ef9a4b198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des masks pour l'évaluation\n",
    "path_mri_t1w_mask = []\n",
    "for i in range (1,5):\n",
    "    path_mri_t1w_mask.append(str(BASE_DIR / \"Skull-Stripping_prediction\" / \"T1\" / str(i) /\"mask.nii.gz\"))\n",
    "          \n",
    "path_mri_t2w_mask = []\n",
    "for i in range (1,5):\n",
    "    path_mri_t2w_mask.append(str(BASE_DIR / \"Skull-Stripping_prediction\" / \"T2\" / str(i) /\"mask.nii.gz\"))\n",
    "                        \n",
    "path_mri_infant_mask = []\n",
    "for i in range (1,5):\n",
    "    path_mri_infant_mask.append(str(BASE_DIR / \"Skull-Stripping_prediction\" / \"INFANT\" / str(i) /\"mask.nii.gz\"))\n",
    "\n",
    "path_mri_flair_mask = []\n",
    "for i in range (1,5):\n",
    "    path_mri_flair_mask.append(str(BASE_DIR / \"Skull-Stripping_prediction\" / \"FLAIR\" / str(i) /\"mask.nii.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b716c668-5cda-4117-be0c-03e022847a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_images = [path_mri_t1w[0], path_mri_t1w[1], path_mri_t2w[0], path_mri_flair[0], path_mri_infant[0]]\n",
    "saved_imgs = []"
   ]
  },
  {
   "cell_type": "raw",
   "id": "81abd33e-35e5-4819-b504-4131059e2cb0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed9c2c94-1a29-43bf-ba49-5dd93e404422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape(path) :\n",
    "    nii_img = nib.load(path)\n",
    "    nii_img_data = nii_img.get_fdata()\n",
    "    np_array_img = np.array(nii_img_data)\n",
    "    return np_array_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "91040ce7-4a00-48d6-9e95-20a6e4e335be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the MRI T1w: (256, 256, 256)\n",
      "Shape of the MRI T2w: (256, 256, 130)\n",
      "Shape of the MRI FLAIR: (432, 512, 23)\n",
      "Shape of the MRI INFANT: (256, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of the MRI T1w: {shape(predict_images[0])}\")\n",
    "print(f\"Shape of the MRI T2w: {shape(predict_images[2])}\")\n",
    "print(f\"Shape of the MRI FLAIR: {shape(predict_images[3])}\")\n",
    "print(f\"Shape of the MRI INFANT: {shape(predict_images[4])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b28b53b-4ff2-4302-a9ba-672f3f679a2b",
   "metadata": {},
   "source": [
    "### 4. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a07a5892-4c64-4568-8555-e79ac117f0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: /home/allan/Licence3_Informatique/LIFPRO/Prediction/Skull-Stripping_prediction/T1/1/image.nii.gz\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'runners' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32mtumor_classifier.ipynb\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0msaved_imgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   original, stripped, mask = runners.infer(image, \n\u001b[0m\u001b[1;32m      7\u001b[0m                                            \u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                            \u001b[0mpatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'runners' is not defined"
     ]
    }
   ],
   "source": [
    "for image in predict_images:\n",
    "  print(f\"Image: {image}\")\n",
    "  save_path = image.split('.')[0] + '_skull_stripped.nii.gz'\n",
    "  saved_imgs.append(save_path)\n",
    "\n",
    "  original, stripped, mask = infer(image, \n",
    "                                   ave_path, model, \n",
    "                                   patch_size=patch_size, \n",
    "                                   overlap=overlap_size, \n",
    "                                   batch_size=batch_size, \n",
    "                                   device=device, \n",
    "                                   visualize=True, \n",
    "                                   return_tensors=True, \n",
    "                                   transforms=valid_transforms)\n",
    "\n",
    "  subject = tio.Subject(mri=tio.ScalarImage(tensor=original))\n",
    "  subject.add_image(tio.ScalarImage(tensor=mask), 'prediction')\n",
    "  subject.add_image(tio.ScalarImage(tensor=stripped), 'skull-stripped')\n",
    "  subject.plot(figsize=(9, 8), cmap_dict={'prediction': 'OrRd'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3aa1113-ee8a-47d7-bd84-8269c8d6bc49",
   "metadata": {},
   "source": [
    "On peut apercevoir que le model ne marche que pour les T1, et pas pour les autres. Il faut donc créer un model pour chaque séquence d'IRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc921e7-1636-4f63-8721-522fca986d34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
