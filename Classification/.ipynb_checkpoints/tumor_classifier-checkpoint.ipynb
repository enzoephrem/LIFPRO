{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "102cf74e-7463-4c41-80ad-b10ffcd2c1a8",
   "metadata": {
    "id": "102cf74e-7463-4c41-80ad-b10ffcd2c1a8"
   },
   "source": [
    "# Brain Tumor Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aZPvf-HxbbMu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aZPvf-HxbbMu",
    "outputId": "8fce5f63-272c-4c71-8882-133972654db0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/',  force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14bf024-61c7-47b9-ae11-9ad78f3c6b4c",
   "metadata": {
    "id": "e14bf024-61c7-47b9-ae11-9ad78f3c6b4c"
   },
   "source": [
    "## 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f97482",
   "metadata": {
    "id": "d7f97482"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import logging\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import logging\n",
    "from keras.models import Sequential, Model\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dropout, Dense, GlobalAveragePooling2D, Conv2D, MaxPool2D, Flatten\n",
    "\n",
    "from keras.applications.resnet import ResNet50\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.efficientnet import EfficientNetB0\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.applications import imagenet_utils\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "E1mceddifao3",
   "metadata": {
    "id": "E1mceddifao3"
   },
   "outputs": [],
   "source": [
    "!cp -r \"/content/drive/MyDrive/LIFPROJET/Classification/dataset\" '/content/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b63324-fa33-4f63-82b5-42fa46c06747",
   "metadata": {
    "id": "c3b63324-fa33-4f63-82b5-42fa46c06747"
   },
   "source": [
    "Ignore Warning : A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f858f297",
   "metadata": {
    "id": "f858f297"
   },
   "outputs": [],
   "source": [
    "__file__ = '/content/drive/MyDrive/LIFPROJET/Classification/tumor_classifier.ipynb'\n",
    "\n",
    "BASE_DIR = Path(__file__).resolve().parent\n",
    "\n",
    "path_training = Path(\"/content/dataset/Training\")\n",
    "path_test = Path(\"/content/dataset/Testing\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c052f2-f013-417c-8eff-b43f16a9a9ca",
   "metadata": {
    "id": "c8c052f2-f013-417c-8eff-b43f16a9a9ca"
   },
   "source": [
    "## 2. Data Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea072c5",
   "metadata": {
    "id": "4ea072c5"
   },
   "outputs": [],
   "source": [
    "X_train = [] # training images\n",
    "y_train  = [] # training labels\n",
    "\n",
    "X_test = [] # testing images\n",
    "y_test = [] # testing labels\n",
    "\n",
    "IMAGE_SIZE = 128\n",
    "\n",
    "classes = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
    "\n",
    "\n",
    "for label in classes:\n",
    "    train_path = path_training / label\n",
    "    list_files_training = os.listdir(str(train_path))\n",
    "    \n",
    "    test_path = path_test / label\n",
    "    list_files_test = os.listdir(str(test_path))\n",
    "    \n",
    "    # Training\n",
    "    for file in list_files_training:\n",
    "        path_image = train_path / file\n",
    "        img = cv2.imread(str(path_image),0) # 0 = gray\n",
    "        \n",
    "        # Produce a pseudocolored image\n",
    "        img = cv2.applyColorMap(img, cv2.COLORMAP_BONE)\n",
    "        \n",
    "        # Resize in case of error in preprocessing\n",
    "        img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "        \n",
    "        X_train.append(img)\n",
    "        y_train.append(classes.index(label))\n",
    "    \n",
    "    # Test         \n",
    "    for file in list_files_test:\n",
    "        path_image = test_path / file\n",
    "        img = cv2.imread(str(path_image),0) # 0 = gray\n",
    "        \n",
    "        # Produce a pseudocolored image\n",
    "        img = cv2.applyColorMap(img, cv2.COLORMAP_BONE)\n",
    "        \n",
    "        # Resize in case of error in preprocessing\n",
    "        img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "        \n",
    "        X_test.append(img)\n",
    "        y_test.append(classes.index(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d6ae2b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b6d6ae2b",
    "outputId": "f1de94fb-41f7-4f0a-a1ec-041bdb64826c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5712, 128, 128, 3)\n",
      "(1310, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "# Convert to numpy array and Normalize into range 0 to 1\n",
    "\n",
    "X_train = np.array(X_train) / 255.0\n",
    "X_test = np.array(X_test) / 255.0\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59886033",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "59886033",
    "outputId": "ca1063f2-ecad-4ff2-debe-62226f7c4b7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1143, 128, 128, 3)\n",
      "(1143, 4)\n"
     ]
    }
   ],
   "source": [
    "# Shuffule images\n",
    "X_train, y_train = shuffle(X_train,y_train, random_state=10) \n",
    "\n",
    "# Initialize tensorflow classes categorical\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "# Dividing dataset into 2 sets : training and validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=10)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe009f8d-d45b-4a15-b729-b5f9abc3b6b5",
   "metadata": {
    "id": "fe009f8d-d45b-4a15-b729-b5f9abc3b6b5"
   },
   "source": [
    "## 3. Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81a3d36",
   "metadata": {
    "id": "c81a3d36"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rotation_range=8,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   width_shift_range=0.05,\n",
    "                                   height_shift_range=0.05,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "train_datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf52c55-58b1-400f-b631-d534462798ae",
   "metadata": {
    "id": "aaf52c55-58b1-400f-b631-d534462798ae"
   },
   "source": [
    "## 4. Convutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bba3a4-72fa-4084-ae9d-a1027cdcc74b",
   "metadata": {
    "id": "46bba3a4-72fa-4084-ae9d-a1027cdcc74b"
   },
   "source": [
    "### 4.1 Model Settings / Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e62e21f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4e62e21f",
    "outputId": "c7155f31-40d3-47ac-f641-ec5fa681d43d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_128_no_top.h5\n",
      "9406464/9406464 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "mobilev2_model = MobileNetV2(weights='imagenet', # Load weights pre-trained on ImageNet.\n",
    "                              include_top=False,\n",
    "                              input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f689ff-afae-4dd2-adff-52c996a3ac62",
   "metadata": {
    "id": "75f689ff-afae-4dd2-adff-52c996a3ac62"
   },
   "source": [
    "### 4.2 Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6570f4b8",
   "metadata": {
    "id": "6570f4b8"
   },
   "outputs": [],
   "source": [
    "classifier_model = mobilev2_model.output\n",
    "\n",
    "classifier_model = GlobalAveragePooling2D()(classifier_model)\n",
    "\n",
    "classifier_model = Dense(units=4, activation=\"softmax\")(classifier_model)\n",
    "\n",
    "classifier_model = tf.keras.Model(inputs= mobilev2_model.input, outputs= classifier_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa7d02a-a5a8-490d-939c-fc1aa9c40f9a",
   "metadata": {
    "id": "6fa7d02a-a5a8-490d-939c-fc1aa9c40f9a"
   },
   "source": [
    "### 4.3 Model Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b95437",
   "metadata": {
    "id": "f1b95437"
   },
   "outputs": [],
   "source": [
    "PRE_TRAINED_MODEL = \"MobileNetV2\"\n",
    "OPTIMIZER = \"SGD\"\n",
    "\n",
    "LOSS = 'categorical_crossentropy'\n",
    "\n",
    "BATCH_SIZE = 2\n",
    "EPOCHS = 15\n",
    "\n",
    "MODEL_NAME = PRE_TRAINED_MODEL + \"_\" + OPTIMIZER + \"_\" + LOSS + \"_\" + str(EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010f7b0f-6fee-4968-946b-3a54e98af15c",
   "metadata": {
    "id": "010f7b0f-6fee-4968-946b-3a54e98af15c"
   },
   "outputs": [],
   "source": [
    "classifier_model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.0001),\n",
    "              loss = LOSS,\n",
    "              metrics=['accuracy'])\n",
    "#classifier_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71df92e5-cf9f-43ab-8820-6092cc5c60ae",
   "metadata": {
    "id": "71df92e5-cf9f-43ab-8820-6092cc5c60ae"
   },
   "source": [
    "### 4.4 Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc90f83b-bf6b-4e34-a2f5-36c6bb181574",
   "metadata": {
    "id": "bc90f83b-bf6b-4e34-a2f5-36c6bb181574"
   },
   "source": [
    "#### 4.4.1 Save checkpoints during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd57a82-470e-4c84-b2c7-83ca28ee1100",
   "metadata": {
    "id": "5bd57a82-470e-4c84-b2c7-83ca28ee1100"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"logs/checkpoints/\" + \"_\" + MODEL_NAME\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                         save_weights_only=True,\n",
    "                                                         verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409bc4fa-4147-4dbf-8542-2c5b0afc6183",
   "metadata": {
    "id": "409bc4fa-4147-4dbf-8542-2c5b0afc6183"
   },
   "source": [
    "#### 4.4.2 Initialize TensorBoard during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0824c9e-5323-4e0e-af79-d377bce6e6a1",
   "metadata": {
    "id": "a0824c9e-5323-4e0e-af79-d377bce6e6a1"
   },
   "outputs": [],
   "source": [
    "log_dir = \"/content/drive/MyDrive/LIFPROJET/Classification/logs/fit/\" + \"_\" + MODEL_NAME\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4508a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3d4508a1",
    "outputId": "3bbd979d-9227-419d-974d-a1025ed7f727"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "2285/2285 [==============================] - 58s 20ms/step - loss: 1.1408 - accuracy: 0.5080 - val_loss: 1.0042 - val_accuracy: 0.5906\n",
      "Epoch 2/15\n",
      "2285/2285 [==============================] - 43s 19ms/step - loss: 0.9608 - accuracy: 0.6211 - val_loss: 0.7340 - val_accuracy: 0.7297\n",
      "Epoch 3/15\n",
      "2285/2285 [==============================] - 44s 19ms/step - loss: 0.8987 - accuracy: 0.6612 - val_loss: 0.7379 - val_accuracy: 0.7218\n",
      "Epoch 4/15\n",
      "2285/2285 [==============================] - 44s 19ms/step - loss: 0.8410 - accuracy: 0.6892 - val_loss: 0.5617 - val_accuracy: 0.7909\n",
      "Epoch 5/15\n",
      "2285/2285 [==============================] - 44s 19ms/step - loss: 0.7851 - accuracy: 0.7196 - val_loss: 0.5513 - val_accuracy: 0.7962\n",
      "Epoch 6/15\n",
      "2285/2285 [==============================] - 44s 19ms/step - loss: 0.7737 - accuracy: 0.7159 - val_loss: 0.4716 - val_accuracy: 0.8320\n",
      "Epoch 7/15\n",
      "2285/2285 [==============================] - 44s 19ms/step - loss: 0.7392 - accuracy: 0.7380 - val_loss: 0.5140 - val_accuracy: 0.8110\n",
      "Epoch 8/15\n",
      "2285/2285 [==============================] - 43s 19ms/step - loss: 0.7284 - accuracy: 0.7441 - val_loss: 0.4869 - val_accuracy: 0.8276\n",
      "Epoch 9/15\n",
      "2285/2285 [==============================] - 43s 19ms/step - loss: 0.6948 - accuracy: 0.7549 - val_loss: 0.4836 - val_accuracy: 0.8224\n",
      "Epoch 10/15\n",
      "2285/2285 [==============================] - 43s 19ms/step - loss: 0.6522 - accuracy: 0.7724 - val_loss: 0.4381 - val_accuracy: 0.8425\n",
      "Epoch 11/15\n",
      "2285/2285 [==============================] - 44s 19ms/step - loss: 0.6602 - accuracy: 0.7730 - val_loss: 0.4152 - val_accuracy: 0.8548\n",
      "Epoch 12/15\n",
      "2285/2285 [==============================] - 43s 19ms/step - loss: 0.6416 - accuracy: 0.7816 - val_loss: 0.4320 - val_accuracy: 0.8434\n",
      "Epoch 13/15\n",
      "2285/2285 [==============================] - 43s 19ms/step - loss: 0.6149 - accuracy: 0.7805 - val_loss: 0.3726 - val_accuracy: 0.8749\n",
      "Epoch 14/15\n",
      "2285/2285 [==============================] - 43s 19ms/step - loss: 0.5853 - accuracy: 0.7967 - val_loss: 0.3519 - val_accuracy: 0.8836\n",
      "Epoch 15/15\n",
      "2285/2285 [==============================] - 43s 19ms/step - loss: 0.5528 - accuracy: 0.8164 - val_loss: 0.3668 - val_accuracy: 0.8749\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff8140bde80>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_model.fit(train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                     validation_data = (X_val,y_val),\n",
    "                     epochs = EPOCHS,\n",
    "                     verbose = 1,\n",
    "                     callbacks=[tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "n_uMVuxDOcvO",
   "metadata": {
    "id": "n_uMVuxDOcvO",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## All the others training models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h8KQEw3VOoes",
   "metadata": {
    "id": "h8KQEw3VOoes"
   },
   "source": [
    "### MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nQo20O_ciBgk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nQo20O_ciBgk",
    "outputId": "bc0e4158-6c88-4013-9c8a-2d44dc028ecf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "Epoch 2/15\n",
      "Epoch 3/15\n",
      "Epoch 4/15\n",
      "Epoch 5/15\n",
      "Epoch 6/15\n",
      "Epoch 7/15\n",
      "Epoch 8/15\n",
      "Epoch 9/15\n",
      "Epoch 10/15\n",
      "Epoch 11/15\n",
      "Epoch 12/15\n",
      "Epoch 13/15\n",
      "Epoch 14/15\n",
      "Epoch 15/15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff75cc23f40>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobilev2_model = MobileNetV2(weights='imagenet', # Load weights pre-trained on ImageNet.\n",
    "                              include_top=False,\n",
    "                              input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "classifier_model = mobilev2_model.output\n",
    "classifier_model = GlobalAveragePooling2D()(classifier_model)\n",
    "classifier_model = Dense(units=4, activation=\"softmax\")(classifier_model)\n",
    "classifier_model = tf.keras.Model(inputs= mobilev2_model.input, outputs= classifier_model)\n",
    "\n",
    "PRE_TRAINED_MODEL = \"MobileNetV2\"\n",
    "OPTIMIZER = \"SGD\"\n",
    "LOSS = 'kl_divergence'\n",
    "\n",
    "\n",
    "MODEL_NAME = PRE_TRAINED_MODEL + \"_\" + OPTIMIZER + \"_\" + LOSS + \"_\" + str(EPOCHS)\n",
    "\n",
    "log_dir = \"/content/drive/MyDrive/LIFPROJET/Classification/logs/fit/\" + \"_\" + MODEL_NAME\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "classifier_model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.0001),\n",
    "              loss = LOSS,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "classifier_model.fit(train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                     validation_data = (X_val,y_val),\n",
    "                     epochs = EPOCHS,\n",
    "                     verbose = 10,\n",
    "                     callbacks=[tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YzYm3Z3ZiBnA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YzYm3Z3ZiBnA",
    "outputId": "f21c931a-4cff-4fc7-f9bf-8c30009555d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "Epoch 2/15\n",
      "Epoch 3/15\n",
      "Epoch 4/15\n",
      "Epoch 5/15\n",
      "Epoch 6/15\n",
      "Epoch 7/15\n",
      "Epoch 8/15\n",
      "Epoch 9/15\n",
      "Epoch 10/15\n",
      "Epoch 11/15\n",
      "Epoch 12/15\n",
      "Epoch 13/15\n",
      "Epoch 14/15\n",
      "Epoch 15/15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff75cdd8e80>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobilev2_model = MobileNetV2(weights='imagenet', # Load weights pre-trained on ImageNet.\n",
    "                              include_top=False,\n",
    "                              input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "\n",
    "classifier_model = mobilev2_model.output\n",
    "classifier_model = GlobalAveragePooling2D()(classifier_model)\n",
    "classifier_model = Dense(units=4, activation=\"softmax\")(classifier_model)\n",
    "classifier_model = tf.keras.Model(inputs= mobilev2_model.input, outputs= classifier_model)\n",
    "\n",
    "PRE_TRAINED_MODEL = \"MobileNetV2\"\n",
    "OPTIMIZER = \"SGD\"\n",
    "LOSS = 'categorical_hinge'\n",
    "\n",
    "\n",
    "MODEL_NAME = PRE_TRAINED_MODEL + \"_\" + OPTIMIZER + \"_\" + LOSS + \"_\" + str(EPOCHS)\n",
    "\n",
    "log_dir = \"/content/drive/MyDrive/LIFPROJET/Classification/logs/fit/\" + \"_\" + MODEL_NAME\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "classifier_model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.0001),\n",
    "              loss = LOSS,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "classifier_model.fit(train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                     validation_data = (X_val,y_val),\n",
    "                     epochs = EPOCHS,\n",
    "                     verbose = 10,\n",
    "                     callbacks=[tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "J6DTAshgiBpB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J6DTAshgiBpB",
    "outputId": "4c3a1421-61ac-4fa7-ec06-1453c45add4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff754e0da30>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobilev2_model = MobileNetV2(weights='imagenet', # Load weights pre-trained on ImageNet.\n",
    "                              include_top=False,\n",
    "                              input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "classifier_model = mobilev2_model.output\n",
    "classifier_model = GlobalAveragePooling2D()(classifier_model)\n",
    "classifier_model = Dense(units=4, activation=\"softmax\")(classifier_model)\n",
    "classifier_model = tf.keras.Model(inputs= mobilev2_model.input, outputs= classifier_model)\n",
    "\n",
    "PRE_TRAINED_MODEL = \"MobileNetV2\"\n",
    "OPTIMIZER = \"Adam\"\n",
    "LOSS = 'categorical_crossentropy'\n",
    "\n",
    "\n",
    "MODEL_NAME = PRE_TRAINED_MODEL + \"_\" + OPTIMIZER + \"_\" + LOSS + \"_\" + str(EPOCHS)\n",
    "\n",
    "log_dir = \"/content/drive/MyDrive/LIFPROJET/Classification/logs/fit/\" + \"_\" + MODEL_NAME\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "classifier_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss = LOSS,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "classifier_model.fit(train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                     validation_data = (X_val,y_val),\n",
    "                     epochs = EPOCHS,\n",
    "                     verbose = 0,\n",
    "                     callbacks=[tensorboard_callback])\n",
    "\n",
    "\n",
    "mobilev2_model = MobileNetV2(weights='imagenet', # Load weights pre-trained on ImageNet.\n",
    "                              include_top=False,\n",
    "                              input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "classifier_model = mobilev2_model.output\n",
    "classifier_model = GlobalAveragePooling2D()(classifier_model)\n",
    "classifier_model = Dense(units=4, activation=\"softmax\")(classifier_model)\n",
    "classifier_model = tf.keras.Model(inputs= mobilev2_model.input, outputs= classifier_model)\n",
    "\n",
    "PRE_TRAINED_MODEL = \"MobileNetV2\"\n",
    "OPTIMIZER = \"Adam\"\n",
    "LOSS = \"kl_divergence\"\n",
    "MODEL_NAME = PRE_TRAINED_MODEL + \"_\" + OPTIMIZER + \"_\" + LOSS + \"_\" + str(EPOCHS)\n",
    "\n",
    "log_dir = \"/content/drive/MyDrive/LIFPROJET/Classification/logs/fit/\" + \"_\" + MODEL_NAME\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "classifier_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss = LOSS,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "classifier_model.fit(train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                     validation_data = (X_val,y_val),\n",
    "                     epochs = EPOCHS,\n",
    "                     verbose = 0,\n",
    "                     callbacks=[tensorboard_callback])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mobilev2_model = MobileNetV2(weights='imagenet', # Load weights pre-trained on ImageNet.\n",
    "                              include_top=False,\n",
    "                              input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "classifier_model = mobilev2_model.output\n",
    "classifier_model = GlobalAveragePooling2D()(classifier_model)\n",
    "classifier_model = Dense(units=4, activation=\"softmax\")(classifier_model)\n",
    "classifier_model = tf.keras.Model(inputs= mobilev2_model.input, outputs= classifier_model)\n",
    "\n",
    "PRE_TRAINED_MODEL = \"MobileNetV2\"\n",
    "OPTIMIZER = \"Adam\"\n",
    "LOSS = \"categorical_hinge\"\n",
    "MODEL_NAME = PRE_TRAINED_MODEL + \"_\" + OPTIMIZER + \"_\" + LOSS + \"_\" + str(EPOCHS)\n",
    "\n",
    "log_dir = \"/content/drive/MyDrive/LIFPROJET/Classification/logs/fit/\" + \"_\" + MODEL_NAME\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "classifier_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss = LOSS,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "classifier_model.fit(train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                     validation_data = (X_val,y_val),\n",
    "                     epochs = EPOCHS,\n",
    "                     verbose = 0,\n",
    "                     callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4rEYKG8kHV0a",
   "metadata": {
    "id": "4rEYKG8kHV0a"
   },
   "outputs": [],
   "source": [
    "mobilev2_model = MobileNetV2(weights='imagenet', # Load weights pre-trained on ImageNet.\n",
    "                              include_top=False,\n",
    "                              input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "classifier_model = mobilev2_model.output\n",
    "classifier_model = GlobalAveragePooling2D()(classifier_model)\n",
    "classifier_model = Dense(units=4, activation=\"softmax\")(classifier_model)\n",
    "classifier_model = tf.keras.Model(inputs= mobilev2_model.input, outputs= classifier_model)\n",
    "\n",
    "PRE_TRAINED_MODEL = \"MobileNetV2\"\n",
    "OPTIMIZER = \"NAdam\"\n",
    "LOSS = 'categorical_crossentropy'\n",
    "\n",
    "\n",
    "\n",
    "MODEL_NAME = PRE_TRAINED_MODEL + \"_\" + OPTIMIZER + \"_\" + LOSS + \"_\" + str(EPOCHS)\n",
    "\n",
    "log_dir = \"/content/drive/MyDrive/LIFPROJET/Classification/logs/fit/\" + \"_\" + MODEL_NAME\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "classifier_model.compile(optimizer=keras.optimizers.Nadam(learning_rate=0.0001),\n",
    "              loss = LOSS,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "classifier_model.fit(train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                     validation_data = (X_val,y_val),\n",
    "                     epochs = EPOCHS,\n",
    "                     verbose = 0,\n",
    "                     callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23xpk7hoiBrR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "23xpk7hoiBrR",
    "outputId": "397bce51-8641-49af-fb90-8087bf38a159"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff754d0bfa0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobilev2_model = MobileNetV2(weights='imagenet', # Load weights pre-trained on ImageNet.\n",
    "                              include_top=False,\n",
    "                              input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "classifier_model = mobilev2_model.output\n",
    "classifier_model = GlobalAveragePooling2D()(classifier_model)\n",
    "classifier_model = Dense(units=4, activation=\"softmax\")(classifier_model)\n",
    "classifier_model = tf.keras.Model(inputs= mobilev2_model.input, outputs= classifier_model)\n",
    "\n",
    "PRE_TRAINED_MODEL = \"MobileNetV2\"\n",
    "OPTIMIZER = \"NAdam\"\n",
    "LOSS = \"kl_divergence\"\n",
    "MODEL_NAME = PRE_TRAINED_MODEL + \"_\" + OPTIMIZER + \"_\" + LOSS + \"_\" + str(EPOCHS)\n",
    "\n",
    "log_dir = \"/content/drive/MyDrive/LIFPROJET/Classification/logs/fit/\" + \"_\" + MODEL_NAME\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "classifier_model.compile(optimizer=keras.optimizers.Nadam(learning_rate=0.0001),\n",
    "              loss = LOSS,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "classifier_model.fit(train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                     validation_data = (X_val,y_val),\n",
    "                     epochs = EPOCHS,\n",
    "                     verbose = 0,\n",
    "                     callbacks=[tensorboard_callback])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mobilev2_model = MobileNetV2(weights='imagenet', # Load weights pre-trained on ImageNet.\n",
    "                              include_top=False,\n",
    "                              input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "classifier_model = mobilev2_model.output\n",
    "classifier_model = GlobalAveragePooling2D()(classifier_model)\n",
    "classifier_model = Dense(units=4, activation=\"softmax\")(classifier_model)\n",
    "classifier_model = tf.keras.Model(inputs= mobilev2_model.input, outputs= classifier_model)\n",
    "\n",
    "PRE_TRAINED_MODEL = \"MobileNetV2\"\n",
    "OPTIMIZER = \"NAdam\"\n",
    "LOSS = \"categorical_hinge\"\n",
    "MODEL_NAME = PRE_TRAINED_MODEL + \"_\" + OPTIMIZER + \"_\" + LOSS + \"_\" + str(EPOCHS)\n",
    "\n",
    "log_dir = \"/content/drive/MyDrive/LIFPROJET/Classification/logs/fit/\" + \"_\" + MODEL_NAME\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "classifier_model.compile(optimizer=keras.optimizers.Nadam(learning_rate=0.0001),\n",
    "              loss = LOSS,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "classifier_model.fit(train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                     validation_data = (X_val,y_val),\n",
    "                     epochs = EPOCHS,\n",
    "                     verbose = 0,\n",
    "                     callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "m2R-GgFiiBuh",
   "metadata": {
    "id": "m2R-GgFiiBuh"
   },
   "outputs": [],
   "source": [
    "\n",
    "#### ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y37ttJHYiByA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y37ttJHYiByA",
    "outputId": "34e49b94-e049-43a4-9cce-309329442e6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 5s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff754b3cac0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_model = ResNet50(weights='imagenet', # Load weights pre-trained on ImageNet.\n",
    "                       include_top=False,\n",
    "                       input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "\n",
    "classifier_model = resnet_model.output\n",
    "classifier_model = GlobalAveragePooling2D()(classifier_model)\n",
    "classifier_model = Dense(units=4, activation=\"softmax\")(classifier_model)\n",
    "classifier_model = tf.keras.Model(inputs= resnet_model.input, outputs= classifier_model)\n",
    "\n",
    "PRE_TRAINED_MODEL = \"ResNet\"\n",
    "OPTIMIZER = \"Adam\"\n",
    "LOSS = \"categorical_crossentropy\"\n",
    "MODEL_NAME = PRE_TRAINED_MODEL + \"_\" + OPTIMIZER + \"_\" + LOSS + \"_\" + str(EPOCHS)\n",
    "\n",
    "log_dir = \"/content/drive/MyDrive/LIFPROJET/Classification/logs/fit/\" + \"_\" + MODEL_NAME\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "classifier_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss = LOSS,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "classifier_model.fit(train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                     validation_data = (X_val,y_val),\n",
    "                     epochs = EPOCHS,\n",
    "                     verbose = 0,\n",
    "                     callbacks=[tensorboard_callback])\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "resnet_model = ResNet50(weights='imagenet', # Load weights pre-trained on ImageNet.\n",
    "                       include_top=False,\n",
    "                       input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "classifier_model = resnet_model.output\n",
    "classifier_model = GlobalAveragePooling2D()(classifier_model)\n",
    "classifier_model = Dense(units=4, activation=\"softmax\")(classifier_model)\n",
    "classifier_model = tf.keras.Model(inputs= resnet_model.input, outputs= classifier_model)\n",
    "\n",
    "PRE_TRAINED_MODEL = \"ResNet\"\n",
    "OPTIMIZER = \"Adam\"\n",
    "LOSS = \"kl_divergence\"\n",
    "MODEL_NAME = PRE_TRAINED_MODEL + \"_\" + OPTIMIZER + \"_\" + LOSS + \"_\" + str(EPOCHS)\n",
    "\n",
    "log_dir = \"/content/drive/MyDrive/LIFPROJET/Classification/logs/fit/\" + \"_\" + MODEL_NAME\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "classifier_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss = LOSS,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "classifier_model.fit(train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                     validation_data = (X_val,y_val),\n",
    "                     epochs = EPOCHS,\n",
    "                     verbose = 0,\n",
    "                     callbacks=[tensorboard_callback])\n",
    "#--------------------------------------------------------------\n",
    "resnet_model = ResNet50(weights='imagenet', # Load weights pre-trained on ImageNet.\n",
    "                       include_top=False,\n",
    "                       input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "classifier_model = resnet_model.output\n",
    "classifier_model = GlobalAveragePooling2D()(classifier_model)\n",
    "classifier_model = Dense(units=4, activation=\"softmax\")(classifier_model)\n",
    "classifier_model = tf.keras.Model(inputs= resnet_model.input, outputs= classifier_model)\n",
    "\n",
    "PRE_TRAINED_MODEL = \"ResNet\"\n",
    "OPTIMIZER = \"Adam\"\n",
    "LOSS = \"categorical_hinge\"\n",
    "MODEL_NAME = PRE_TRAINED_MODEL + \"_\" + OPTIMIZER + \"_\" + LOSS + \"_\" + str(EPOCHS)\n",
    "\n",
    "log_dir = \"/content/drive/MyDrive/LIFPROJET/Classification/logs/fit/\" + \"_\" + MODEL_NAME\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "classifier_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss = LOSS,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "classifier_model.fit(train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                     validation_data = (X_val,y_val),\n",
    "                     epochs = EPOCHS,\n",
    "                     verbose = 0,\n",
    "                     callbacks=[tensorboard_callback])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------\n",
    "#--------------------------------------------------------------\n",
    "#--------------------------------------------------------------\n",
    "resnet_model = ResNet50(weights='imagenet', # Load weights pre-trained on ImageNet.\n",
    "                       include_top=False,\n",
    "                       input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "classifier_model = resnet_model.output\n",
    "classifier_model = GlobalAveragePooling2D()(classifier_model)\n",
    "classifier_model = Dense(units=4, activation=\"softmax\")(classifier_model)\n",
    "classifier_model = tf.keras.Model(inputs= resnet_model.input, outputs= classifier_model)\n",
    "\n",
    "PRE_TRAINED_MODEL = \"ResNet\"\n",
    "OPTIMIZER = \"NAdam\"\n",
    "LOSS = \"categorical_crossentropy\"\n",
    "MODEL_NAME = PRE_TRAINED_MODEL + \"_\" + OPTIMIZER + \"_\" + LOSS + \"_\" + str(EPOCHS)\n",
    "\n",
    "log_dir = \"/content/drive/MyDrive/LIFPROJET/Classification/logs/fit/\" + \"_\" + MODEL_NAME\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "classifier_model.compile(optimizer=keras.optimizers.Nadam(learning_rate=0.0001),\n",
    "              loss = LOSS,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "classifier_model.fit(train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                     validation_data = (X_val,y_val),\n",
    "                     epochs = EPOCHS,\n",
    "                     verbose = 0,\n",
    "                     callbacks=[tensorboard_callback])\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "resnet_model = ResNet50(weights='imagenet', # Load weights pre-trained on ImageNet.\n",
    "                       include_top=False,\n",
    "                       input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "classifier_model = resnet_model.output\n",
    "classifier_model = GlobalAveragePooling2D()(classifier_model)\n",
    "classifier_model = Dense(units=4, activation=\"softmax\")(classifier_model)\n",
    "classifier_model = tf.keras.Model(inputs= resnet_model.input, outputs= classifier_model)\n",
    "\n",
    "PRE_TRAINED_MODEL = \"ResNet\"\n",
    "OPTIMIZER = \"NAdam\"\n",
    "LOSS = \"kl_divergence\"\n",
    "MODEL_NAME = PRE_TRAINED_MODEL + \"_\" + OPTIMIZER + \"_\" + LOSS + \"_\" + str(EPOCHS)\n",
    "\n",
    "log_dir = \"/content/drive/MyDrive/LIFPROJET/Classification/logs/fit/\" + \"_\" + MODEL_NAME\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "classifier_model.compile(optimizer=keras.optimizers.Nadam(learning_rate=0.0001),\n",
    "              loss = LOSS,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "classifier_model.fit(train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                     validation_data = (X_val,y_val),\n",
    "                     epochs = EPOCHS,\n",
    "                     verbose = 0,\n",
    "                     callbacks=[tensorboard_callback])\n",
    "#--------------------------------------------------------------\n",
    "resnet_model = ResNet50(weights='imagenet', # Load weights pre-trained on ImageNet.\n",
    "                       include_top=False,\n",
    "                       input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "classifier_model = resnet_model.output\n",
    "classifier_model = GlobalAveragePooling2D()(classifier_model)\n",
    "classifier_model = Dense(units=4, activation=\"softmax\")(classifier_model)\n",
    "classifier_model = tf.keras.Model(inputs= resnet_model.input, outputs= classifier_model)\n",
    "\n",
    "PRE_TRAINED_MODEL = \"ResNet\"\n",
    "OPTIMIZER = \"NAdam\"\n",
    "LOSS = \"categorical_hinge\"\n",
    "MODEL_NAME = PRE_TRAINED_MODEL + \"_\" + OPTIMIZER + \"_\" + LOSS + \"_\" + str(EPOCHS)\n",
    "\n",
    "log_dir = \"/content/drive/MyDrive/LIFPROJET/Classification/logs/fit/\" + \"_\" + MODEL_NAME\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "classifier_model.compile(optimizer=keras.optimizers.Nadam(learning_rate=0.0001),\n",
    "              loss = LOSS,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "classifier_model.fit(train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                     validation_data = (X_val,y_val),\n",
    "                     epochs = EPOCHS,\n",
    "                     verbose = 0,\n",
    "                     callbacks=[tensorboard_callback])\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------\n",
    "#--------------------------------------------------------------\n",
    "#--------------------------------------------------------------\n",
    "resnet_model = ResNet50(weights='imagenet', # Load weights pre-trained on ImageNet.\n",
    "                       include_top=False,\n",
    "                       input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "classifier_model = resnet_model.output\n",
    "classifier_model = GlobalAveragePooling2D()(classifier_model)\n",
    "classifier_model = Dense(units=4, activation=\"softmax\")(classifier_model)\n",
    "classifier_model = tf.keras.Model(inputs= resnet_model.input, outputs= classifier_model)\n",
    "\n",
    "PRE_TRAINED_MODEL = \"ResNet\"\n",
    "OPTIMIZER = \"SGD\"\n",
    "LOSS = \"categorical_crossentropy\"\n",
    "MODEL_NAME = PRE_TRAINED_MODEL + \"_\" + OPTIMIZER + \"_\" + LOSS + \"_\" + str(EPOCHS)\n",
    "\n",
    "log_dir = \"/content/drive/MyDrive/LIFPROJET/Classification/logs/fit/\" + \"_\" + MODEL_NAME\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "classifier_model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.0001),\n",
    "              loss = LOSS,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "classifier_model.fit(train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                     validation_data = (X_val,y_val),\n",
    "                     epochs = EPOCHS,\n",
    "                     verbose = 0,\n",
    "                     callbacks=[tensorboard_callback])\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "resnet_model = ResNet50(weights='imagenet', # Load weights pre-trained on ImageNet.\n",
    "                       include_top=False,\n",
    "                       input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "classifier_model = resnet_model.output\n",
    "classifier_model = GlobalAveragePooling2D()(classifier_model)\n",
    "classifier_model = Dense(units=4, activation=\"softmax\")(classifier_model)\n",
    "classifier_model = tf.keras.Model(inputs= resnet_model.input, outputs= classifier_model)\n",
    "\n",
    "PRE_TRAINED_MODEL = \"ResNet\"\n",
    "OPTIMIZER = \"SGD\"\n",
    "LOSS = \"kl_divergence\"\n",
    "MODEL_NAME = PRE_TRAINED_MODEL + \"_\" + OPTIMIZER + \"_\" + LOSS + \"_\" + str(EPOCHS)\n",
    "\n",
    "log_dir = \"/content/drive/MyDrive/LIFPROJET/Classification/logs/fit/\" + \"_\" + MODEL_NAME\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "classifier_model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.0001),\n",
    "              loss = LOSS,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "classifier_model.fit(train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                     validation_data = (X_val,y_val),\n",
    "                     epochs = EPOCHS,\n",
    "                     verbose = 0,\n",
    "                     callbacks=[tensorboard_callback])\n",
    "#--------------------------------------------------------------\n",
    "resnet_model = ResNet50(weights='imagenet', # Load weights pre-trained on ImageNet.\n",
    "                       include_top=False,\n",
    "                       input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "classifier_model = resnet_model.output\n",
    "classifier_model = GlobalAveragePooling2D()(classifier_model)\n",
    "classifier_model = Dense(units=4, activation=\"softmax\")(classifier_model)\n",
    "classifier_model = tf.keras.Model(inputs= resnet_model.input, outputs= classifier_model)\n",
    "\n",
    "PRE_TRAINED_MODEL = \"ResNet\"\n",
    "OPTIMIZER = \"SGD\"\n",
    "LOSS = \"categorical_hinge\"\n",
    "MODEL_NAME = PRE_TRAINED_MODEL + \"_\" + OPTIMIZER + \"_\" + LOSS + \"_\" + str(EPOCHS)\n",
    "\n",
    "log_dir = \"/content/drive/MyDrive/LIFPROJET/Classification/logs/fit/\" + \"_\" + MODEL_NAME\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "classifier_model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.0001),\n",
    "              loss = LOSS,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "classifier_model.fit(train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                     validation_data = (X_val,y_val),\n",
    "                     epochs = EPOCHS,\n",
    "                     verbose = 0,\n",
    "                     callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PrcAUvnhAnBM",
   "metadata": {
    "id": "PrcAUvnhAnBM"
   },
   "source": [
    "### VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KuzC4vnPp0xj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KuzC4vnPp0xj",
    "outputId": "27846981-9c8c-4dbf-9bc2-3154fd33a0a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 3s 0us/step\n",
      "Epoch 1/15\n",
      "2285/2285 [==============================] - 23s 9ms/step - loss: 0.9359 - accuracy: 0.5877 - val_loss: 0.5686 - val_accuracy: 0.7717\n",
      "Epoch 2/15\n",
      "2285/2285 [==============================] - 20s 9ms/step - loss: 0.5171 - accuracy: 0.8113 - val_loss: 0.3222 - val_accuracy: 0.8871\n",
      "Epoch 3/15\n",
      "2285/2285 [==============================] - 20s 9ms/step - loss: 0.3611 - accuracy: 0.8774 - val_loss: 0.2293 - val_accuracy: 0.9160\n",
      "Epoch 4/15\n",
      "2285/2285 [==============================] - 20s 9ms/step - loss: 0.2729 - accuracy: 0.9079 - val_loss: 0.2610 - val_accuracy: 0.9090\n",
      "Epoch 5/15\n",
      "2285/2285 [==============================] - 20s 9ms/step - loss: 0.2328 - accuracy: 0.9212 - val_loss: 0.3291 - val_accuracy: 0.8898\n",
      "Epoch 6/15\n",
      "2285/2285 [==============================] - 21s 9ms/step - loss: 0.2042 - accuracy: 0.9339 - val_loss: 0.2695 - val_accuracy: 0.9283\n",
      "Epoch 7/15\n",
      "2285/2285 [==============================] - 21s 9ms/step - loss: 0.1697 - accuracy: 0.9416 - val_loss: 0.2091 - val_accuracy: 0.9379\n",
      "Epoch 8/15\n",
      "2285/2285 [==============================] - 21s 9ms/step - loss: 0.1691 - accuracy: 0.9468 - val_loss: 0.9296 - val_accuracy: 0.8093\n",
      "Epoch 9/15\n",
      "2285/2285 [==============================] - 21s 9ms/step - loss: 0.1309 - accuracy: 0.9547 - val_loss: 0.2580 - val_accuracy: 0.9335\n",
      "Epoch 10/15\n",
      "2285/2285 [==============================] - 21s 9ms/step - loss: 0.1357 - accuracy: 0.9543 - val_loss: 0.1553 - val_accuracy: 0.9589\n",
      "Epoch 11/15\n",
      "2285/2285 [==============================] - 20s 9ms/step - loss: 0.1179 - accuracy: 0.9634 - val_loss: 0.1480 - val_accuracy: 0.9694\n",
      "Epoch 12/15\n",
      "2285/2285 [==============================] - 20s 9ms/step - loss: 0.1220 - accuracy: 0.9617 - val_loss: 0.1636 - val_accuracy: 0.9571\n",
      "Epoch 13/15\n",
      "2285/2285 [==============================] - 20s 9ms/step - loss: 0.1053 - accuracy: 0.9648 - val_loss: 0.3172 - val_accuracy: 0.9213\n",
      "Epoch 14/15\n",
      "2285/2285 [==============================] - 20s 9ms/step - loss: 0.0998 - accuracy: 0.9663 - val_loss: 0.1570 - val_accuracy: 0.9659\n",
      "Epoch 15/15\n",
      "2285/2285 [==============================] - 20s 9ms/step - loss: 0.0913 - accuracy: 0.9733 - val_loss: 0.1920 - val_accuracy: 0.9746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff6fe7a9e20>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model = VGG16(weights='imagenet', # Load weights pre-trained on ImageNet.\n",
    "                       include_top=False,\n",
    "                       input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "\n",
    "classifier_model = vgg_model.output\n",
    "classifier_model = GlobalAveragePooling2D()(classifier_model)\n",
    "classifier_model = Dense(units=4, activation=\"softmax\")(classifier_model)\n",
    "classifier_model = tf.keras.Model(inputs= vgg_model.input, outputs= classifier_model)\n",
    "\n",
    "PRE_TRAINED_MODEL = \"VGG16\"\n",
    "OPTIMIZER = \"Adam\"\n",
    "LOSS = \"categorical_crossentropy\"\n",
    "MODEL_NAME = PRE_TRAINED_MODEL + \"_\" + OPTIMIZER + \"_\" + LOSS + \"_\" + str(EPOCHS)\n",
    "\n",
    "log_dir = \"/content/drive/MyDrive/LIFPROJET/Classification/logs/fit/\" + \"_\" + MODEL_NAME\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "classifier_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss = LOSS,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "classifier_model.fit(train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                     validation_data = (X_val,y_val),\n",
    "                     epochs = EPOCHS,\n",
    "                     verbose = 1,\n",
    "                     callbacks=[tensorboard_callback])\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "vgg_model = VGG16(weights='imagenet', # Load weights pre-trained on ImageNet.\n",
    "                       include_top=False,\n",
    "                       input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "classifier_model = vgg_model.output\n",
    "classifier_model = GlobalAveragePooling2D()(classifier_model)\n",
    "classifier_model = Dense(units=4, activation=\"softmax\")(classifier_model)\n",
    "classifier_model = tf.keras.Model(inputs= vgg_model.input, outputs= classifier_model)\n",
    "\n",
    "PRE_TRAINED_MODEL = \"VGG16\"\n",
    "OPTIMIZER = \"Adam\"\n",
    "LOSS = \"kl_divergence\"\n",
    "MODEL_NAME = PRE_TRAINED_MODEL + \"_\" + OPTIMIZER + \"_\" + LOSS + \"_\" + str(EPOCHS)\n",
    "\n",
    "log_dir = \"/content/drive/MyDrive/LIFPROJET/Classification/logs/fit/\" + \"_\" + MODEL_NAME\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "classifier_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss = LOSS,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "classifier_model.fit(train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                     validation_data = (X_val,y_val),\n",
    "                     epochs = EPOCHS,\n",
    "                     verbose = 0,\n",
    "                     callbacks=[tensorboard_callback])\n",
    "#--------------------------------------------------------------\n",
    "vgg_model = VGG16(weights='imagenet', # Load weights pre-trained on ImageNet.\n",
    "                       include_top=False,\n",
    "                       input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "classifier_model = vgg_model.output\n",
    "classifier_model = GlobalAveragePooling2D()(classifier_model)\n",
    "classifier_model = Dense(units=4, activation=\"softmax\")(classifier_model)\n",
    "classifier_model = tf.keras.Model(inputs= vgg_model.input, outputs= classifier_model)\n",
    "\n",
    "PRE_TRAINED_MODEL = \"VGG16\"\n",
    "OPTIMIZER = \"Adam\"\n",
    "LOSS = \"categorical_hinge\"\n",
    "MODEL_NAME = PRE_TRAINED_MODEL + \"_\" + OPTIMIZER + \"_\" + LOSS + \"_\" + str(EPOCHS)\n",
    "\n",
    "log_dir = \"/content/drive/MyDrive/LIFPROJET/Classification/logs/fit/\" + \"_\" + MODEL_NAME\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "classifier_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss = LOSS,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "classifier_model.fit(train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                     validation_data = (X_val,y_val),\n",
    "                     epochs = EPOCHS,\n",
    "                     verbose = 0,\n",
    "                     callbacks=[tensorboard_callback])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------\n",
    "#--------------------------------------------------------------\n",
    "#--------------------------------------------------------------\n",
    "vgg_model = VGG16(weights='imagenet', # Load weights pre-trained on ImageNet.\n",
    "                       include_top=False,\n",
    "                       input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "classifier_model = vgg_model.output\n",
    "classifier_model = GlobalAveragePooling2D()(classifier_model)\n",
    "classifier_model = Dense(units=4, activation=\"softmax\")(classifier_model)\n",
    "classifier_model = tf.keras.Model(inputs= vgg_model.input, outputs= classifier_model)\n",
    "\n",
    "PRE_TRAINED_MODEL = \"VGG16\"\n",
    "OPTIMIZER = \"NAdam\"\n",
    "LOSS = \"categorical_crossentropy\"\n",
    "MODEL_NAME = PRE_TRAINED_MODEL + \"_\" + OPTIMIZER + \"_\" + LOSS + \"_\" + str(EPOCHS)\n",
    "\n",
    "log_dir = \"/content/drive/MyDrive/LIFPROJET/Classification/logs/fit/\" + \"_\" + MODEL_NAME\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "classifier_model.compile(optimizer=keras.optimizers.Nadam(learning_rate=0.0001),\n",
    "              loss = LOSS,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "classifier_model.fit(train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                     validation_data = (X_val,y_val),\n",
    "                     epochs = EPOCHS,\n",
    "                     verbose = 0,\n",
    "                     callbacks=[tensorboard_callback])\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "vgg_model = VGG16(weights='imagenet', # Load weights pre-trained on ImageNet.\n",
    "                       include_top=False,\n",
    "                       input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "classifier_model = vgg_model.output\n",
    "classifier_model = GlobalAveragePooling2D()(classifier_model)\n",
    "classifier_model = Dense(units=4, activation=\"softmax\")(classifier_model)\n",
    "classifier_model = tf.keras.Model(inputs= vgg_model.input, outputs= classifier_model)\n",
    "\n",
    "PRE_TRAINED_MODEL = \"VGG16\"\n",
    "OPTIMIZER = \"NAdam\"\n",
    "LOSS = \"kl_divergence\"\n",
    "MODEL_NAME = PRE_TRAINED_MODEL + \"_\" + OPTIMIZER + \"_\" + LOSS + \"_\" + str(EPOCHS)\n",
    "\n",
    "log_dir = \"/content/drive/MyDrive/LIFPROJET/Classification/logs/fit/\" + \"_\" + MODEL_NAME\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "classifier_model.compile(optimizer=keras.optimizers.Nadam(learning_rate=0.0001),\n",
    "              loss = LOSS,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "classifier_model.fit(train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                     validation_data = (X_val,y_val),\n",
    "                     epochs = EPOCHS,\n",
    "                     verbose = 0,\n",
    "                     callbacks=[tensorboard_callback])\n",
    "#--------------------------------------------------------------\n",
    "vgg_model = VGG16(weights='imagenet', # Load weights pre-trained on ImageNet.\n",
    "                       include_top=False,\n",
    "                       input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "classifier_model = vgg_model.output\n",
    "classifier_model = GlobalAveragePooling2D()(classifier_model)\n",
    "classifier_model = Dense(units=4, activation=\"softmax\")(classifier_model)\n",
    "classifier_model = tf.keras.Model(inputs= vgg_model.input, outputs= classifier_model)\n",
    "\n",
    "PRE_TRAINED_MODEL = \"VGG16\"\n",
    "OPTIMIZER = \"NAdam\"\n",
    "LOSS = \"categorical_hinge\"\n",
    "MODEL_NAME = PRE_TRAINED_MODEL + \"_\" + OPTIMIZER + \"_\" + LOSS + \"_\" + str(EPOCHS)\n",
    "\n",
    "log_dir = \"/content/drive/MyDrive/LIFPROJET/Classification/logs/fit/\" + \"_\" + MODEL_NAME\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "classifier_model.compile(optimizer=keras.optimizers.Nadam(learning_rate=0.0001),\n",
    "              loss = LOSS,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "classifier_model.fit(train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                     validation_data = (X_val,y_val),\n",
    "                     epochs = EPOCHS,\n",
    "                     verbose = 0,\n",
    "                     callbacks=[tensorboard_callback])\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------\n",
    "#--------------------------------------------------------------\n",
    "#--------------------------------------------------------------\n",
    "vgg_model = VGG16(weights='imagenet', # Load weights pre-trained on ImageNet.\n",
    "                       include_top=False,\n",
    "                       input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "classifier_model = vgg_model.output\n",
    "classifier_model = GlobalAveragePooling2D()(classifier_model)\n",
    "classifier_model = Dense(units=4, activation=\"softmax\")(classifier_model)\n",
    "classifier_model = tf.keras.Model(inputs= vgg_model.input, outputs= classifier_model)\n",
    "\n",
    "PRE_TRAINED_MODEL = \"VGG16\"\n",
    "OPTIMIZER = \"SGD\"\n",
    "LOSS = \"categorical_crossentropy\"\n",
    "MODEL_NAME = PRE_TRAINED_MODEL + \"_\" + OPTIMIZER + \"_\" + LOSS + \"_\" + str(EPOCHS)\n",
    "\n",
    "log_dir = \"/content/drive/MyDrive/LIFPROJET/Classification/logs/fit/\" + \"_\" + MODEL_NAME\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "classifier_model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.0001),\n",
    "              loss = LOSS,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "classifier_model.fit(train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                     validation_data = (X_val,y_val),\n",
    "                     epochs = EPOCHS,\n",
    "                     verbose = 0,\n",
    "                     callbacks=[tensorboard_callback])\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "vgg_model = VGG16(weights='imagenet', # Load weights pre-trained on ImageNet.\n",
    "                       include_top=False,\n",
    "                       input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "classifier_model = vgg_model.output\n",
    "classifier_model = GlobalAveragePooling2D()(classifier_model)\n",
    "classifier_model = Dense(units=4, activation=\"softmax\")(classifier_model)\n",
    "classifier_model = tf.keras.Model(inputs= vgg_model.input, outputs= classifier_model)\n",
    "\n",
    "PRE_TRAINED_MODEL = \"VGG16\"\n",
    "OPTIMIZER = \"SGD\"\n",
    "LOSS = \"kl_divergence\"\n",
    "MODEL_NAME = PRE_TRAINED_MODEL + \"_\" + OPTIMIZER + \"_\" + LOSS + \"_\" + str(EPOCHS)\n",
    "\n",
    "log_dir = \"/content/drive/MyDrive/LIFPROJET/Classification/logs/fit/\" + \"_\" + MODEL_NAME\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "classifier_model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.0001),\n",
    "              loss = LOSS,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "classifier_model.fit(train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                     validation_data = (X_val,y_val),\n",
    "                     epochs = EPOCHS,\n",
    "                     verbose = 0,\n",
    "                     callbacks=[tensorboard_callback])\n",
    "#--------------------------------------------------------------\n",
    "vgg_model = VGG16(weights='imagenet', # Load weights pre-trained on ImageNet.\n",
    "                       include_top=False,\n",
    "                       input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "classifier_model = vgg_model.output\n",
    "classifier_model = GlobalAveragePooling2D()(classifier_model)\n",
    "classifier_model = Dense(units=4, activation=\"softmax\")(classifier_model)\n",
    "classifier_model = tf.keras.Model(inputs= vgg_model.input, outputs= classifier_model)\n",
    "\n",
    "PRE_TRAINED_MODEL = \"VGG16\"\n",
    "OPTIMIZER = \"SGD\"\n",
    "LOSS = \"categorical_hinge\"\n",
    "MODEL_NAME = PRE_TRAINED_MODEL + \"_\" + OPTIMIZER + \"_\" + LOSS + \"_\" + str(EPOCHS)\n",
    "\n",
    "log_dir = \"/content/drive/MyDrive/LIFPROJET/Classification/logs/fit/\" + \"_\" + MODEL_NAME\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "classifier_model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.0001),\n",
    "              loss = LOSS,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "classifier_model.fit(train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                     validation_data = (X_val,y_val),\n",
    "                     epochs = EPOCHS,\n",
    "                     verbose = 0,\n",
    "                     callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LN1lx7Nap0zW",
   "metadata": {
    "id": "LN1lx7Nap0zW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "zjmjaU2U_rxQ",
   "metadata": {
    "id": "zjmjaU2U_rxQ"
   },
   "source": [
    "### EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DJbUSr7-p03U",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DJbUSr7-p03U",
    "outputId": "98496f59-e30c-47e8-a046-f8cd44958f33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "16705208/16705208 [==============================] - 2s 0us/step\n",
      "Epoch 1/15\n",
      "2285/2285 [==============================] - 104s 41ms/step - loss: 0.6896 - accuracy: 0.7417 - val_loss: 15.9212 - val_accuracy: 0.2983\n",
      "Epoch 2/15\n",
      "2285/2285 [==============================] - 92s 40ms/step - loss: 0.3174 - accuracy: 0.8884 - val_loss: 1.7505 - val_accuracy: 0.2633\n",
      "Epoch 3/15\n",
      "2285/2285 [==============================] - 93s 41ms/step - loss: 0.2189 - accuracy: 0.9179 - val_loss: 1.2580 - val_accuracy: 0.3823\n",
      "Epoch 4/15\n",
      "2285/2285 [==============================] - 93s 41ms/step - loss: 0.1752 - accuracy: 0.9398 - val_loss: 1.3350 - val_accuracy: 0.3010\n",
      "Epoch 5/15\n",
      "2285/2285 [==============================] - 92s 40ms/step - loss: 0.1488 - accuracy: 0.9464 - val_loss: 7.1838 - val_accuracy: 0.3097\n",
      "Epoch 6/15\n",
      "2285/2285 [==============================] - 93s 41ms/step - loss: 0.1310 - accuracy: 0.9545 - val_loss: 1.3528 - val_accuracy: 0.4462\n",
      "Epoch 7/15\n",
      "2285/2285 [==============================] - 93s 41ms/step - loss: 0.1039 - accuracy: 0.9648 - val_loss: 2.0710 - val_accuracy: 0.2703\n",
      "Epoch 8/15\n",
      "2285/2285 [==============================] - 92s 40ms/step - loss: 0.0923 - accuracy: 0.9689 - val_loss: 44.4691 - val_accuracy: 0.3316\n",
      "Epoch 9/15\n",
      "2285/2285 [==============================] - 92s 40ms/step - loss: 0.0839 - accuracy: 0.9726 - val_loss: 1.5718 - val_accuracy: 0.2852\n",
      "Epoch 10/15\n",
      "2285/2285 [==============================] - 93s 40ms/step - loss: 0.0810 - accuracy: 0.9737 - val_loss: 2.1863 - val_accuracy: 0.2791\n",
      "Epoch 11/15\n",
      "2285/2285 [==============================] - 93s 41ms/step - loss: 0.0702 - accuracy: 0.9768 - val_loss: 2.0000 - val_accuracy: 0.3211\n",
      "Epoch 12/15\n",
      "2285/2285 [==============================] - 92s 40ms/step - loss: 0.0651 - accuracy: 0.9794 - val_loss: 1.5576 - val_accuracy: 0.2686\n",
      "Epoch 13/15\n",
      "2285/2285 [==============================] - 92s 40ms/step - loss: 0.0621 - accuracy: 0.9799 - val_loss: 2.1261 - val_accuracy: 0.2712\n",
      "Epoch 14/15\n",
      "2285/2285 [==============================] - 93s 41ms/step - loss: 0.0602 - accuracy: 0.9816 - val_loss: 1.3695 - val_accuracy: 0.2905\n",
      "Epoch 15/15\n",
      "2285/2285 [==============================] - 93s 41ms/step - loss: 0.0546 - accuracy: 0.9810 - val_loss: 1.7898 - val_accuracy: 0.3045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff74e904250>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eff_model = EfficientNetB0(weights='imagenet', # Load weights pre-trained on ImageNet.\n",
    "                      include_top=False,\n",
    "                      input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "\n",
    "classifier_model = eff_model.output\n",
    "classifier_model = GlobalAveragePooling2D()(classifier_model)\n",
    "classifier_model = Dense(units=4, activation=\"softmax\")(classifier_model)\n",
    "classifier_model = tf.keras.Model(inputs= eff_model.input, outputs= classifier_model)\n",
    "\n",
    "PRE_TRAINED_MODEL = \"EfficientNetB0\"\n",
    "OPTIMIZER = \"Adam\"\n",
    "LOSS = \"categorical_crossentropy\"\n",
    "MODEL_NAME = PRE_TRAINED_MODEL + \"_\" + OPTIMIZER + \"_\" + LOSS + \"_\" + str(EPOCHS)\n",
    "\n",
    "log_dir = \"/content/drive/MyDrive/LIFPROJET/Classification/logs/fit/\" + \"_\" + MODEL_NAME\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "classifier_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss = LOSS,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "classifier_model.fit(train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                     validation_data = (X_val,y_val),\n",
    "                     epochs = EPOCHS,\n",
    "                     verbose = 1,\n",
    "                     callbacks=[tensorboard_callback])\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "eff_model = EfficientNetB0(weights='imagenet', # Load weights pre-trained on ImageNet.\n",
    "                      include_top=False,\n",
    "                      input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "classifier_model = eff_model.output\n",
    "classifier_model = GlobalAveragePooling2D()(classifier_model)\n",
    "classifier_model = Dense(units=4, activation=\"softmax\")(classifier_model)\n",
    "classifier_model = tf.keras.Model(inputs= eff_model.input, outputs= classifier_model)\n",
    "\n",
    "PRE_TRAINED_MODEL = \"EfficientNetB0\"\n",
    "OPTIMIZER = \"Adam\"\n",
    "LOSS = \"kl_divergence\"\n",
    "MODEL_NAME = PRE_TRAINED_MODEL + \"_\" + OPTIMIZER + \"_\" + LOSS + \"_\" + str(EPOCHS)\n",
    "\n",
    "log_dir = \"/content/drive/MyDrive/LIFPROJET/Classification/logs/fit/\" + \"_\" + MODEL_NAME\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "classifier_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss = LOSS,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "classifier_model.fit(train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                     validation_data = (X_val,y_val),\n",
    "                     epochs = EPOCHS,\n",
    "                     verbose = 0,\n",
    "                     callbacks=[tensorboard_callback])\n",
    "#--------------------------------------------------------------\n",
    "eff_model = EfficientNetB0(weights='imagenet', # Load weights pre-trained on ImageNet.\n",
    "                      include_top=False,\n",
    "                      input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "classifier_model = eff_model.output\n",
    "classifier_model = GlobalAveragePooling2D()(classifier_model)\n",
    "classifier_model = Dense(units=4, activation=\"softmax\")(classifier_model)\n",
    "classifier_model = tf.keras.Model(inputs= eff_model.input, outputs= classifier_model)\n",
    "\n",
    "PRE_TRAINED_MODEL = \"EfficientNetB0\"\n",
    "OPTIMIZER = \"Adam\"\n",
    "LOSS = \"categorical_hinge\"\n",
    "MODEL_NAME = PRE_TRAINED_MODEL + \"_\" + OPTIMIZER + \"_\" + LOSS + \"_\" + str(EPOCHS)\n",
    "\n",
    "log_dir = \"/content/drive/MyDrive/LIFPROJET/Classification/logs/fit/\" + \"_\" + MODEL_NAME\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "classifier_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss = LOSS,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "classifier_model.fit(train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                     validation_data = (X_val,y_val),\n",
    "                     epochs = EPOCHS,\n",
    "                     verbose = 0,\n",
    "                     callbacks=[tensorboard_callback])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------\n",
    "#--------------------------------------------------------------\n",
    "#--------------------------------------------------------------\n",
    "eff_model = EfficientNetB0(weights='imagenet', # Load weights pre-trained on ImageNet.\n",
    "                      include_top=False,\n",
    "                      input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "classifier_model = eff_model.output\n",
    "classifier_model = GlobalAveragePooling2D()(classifier_model)\n",
    "classifier_model = Dense(units=4, activation=\"softmax\")(classifier_model)\n",
    "classifier_model = tf.keras.Model(inputs= eff_model.input, outputs= classifier_model)\n",
    "\n",
    "PRE_TRAINED_MODEL = \"EfficientNetB0\"\n",
    "OPTIMIZER = \"NAdam\"\n",
    "LOSS = \"categorical_crossentropy\"\n",
    "MODEL_NAME = PRE_TRAINED_MODEL + \"_\" + OPTIMIZER + \"_\" + LOSS + \"_\" + str(EPOCHS)\n",
    "\n",
    "log_dir = \"/content/drive/MyDrive/LIFPROJET/Classification/logs/fit/\" + \"_\" + MODEL_NAME\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "classifier_model.compile(optimizer=keras.optimizers.Nadam(learning_rate=0.0001),\n",
    "              loss = LOSS,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "classifier_model.fit(train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                     validation_data = (X_val,y_val),\n",
    "                     epochs = EPOCHS,\n",
    "                     verbose = 0,\n",
    "                     callbacks=[tensorboard_callback])\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "eff_model = EfficientNetB0(weights='imagenet', # Load weights pre-trained on ImageNet.\n",
    "                      include_top=False,\n",
    "                      input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "classifier_model = eff_model.output\n",
    "classifier_model = GlobalAveragePooling2D()(classifier_model)\n",
    "classifier_model = Dense(units=4, activation=\"softmax\")(classifier_model)\n",
    "classifier_model = tf.keras.Model(inputs= eff_model.input, outputs= classifier_model)\n",
    "\n",
    "PRE_TRAINED_MODEL = \"EfficientNetB0\"\n",
    "OPTIMIZER = \"NAdam\"\n",
    "LOSS = \"kl_divergence\"\n",
    "MODEL_NAME = PRE_TRAINED_MODEL + \"_\" + OPTIMIZER + \"_\" + LOSS + \"_\" + str(EPOCHS)\n",
    "\n",
    "log_dir = \"/content/drive/MyDrive/LIFPROJET/Classification/logs/fit/\" + \"_\" + MODEL_NAME\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "classifier_model.compile(optimizer=keras.optimizers.Nadam(learning_rate=0.0001),\n",
    "              loss = LOSS,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "classifier_model.fit(train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                     validation_data = (X_val,y_val),\n",
    "                     epochs = EPOCHS,\n",
    "                     verbose = 0,\n",
    "                     callbacks=[tensorboard_callback])\n",
    "#--------------------------------------------------------------\n",
    "eff_model = EfficientNetB0(weights='imagenet', # Load weights pre-trained on ImageNet.\n",
    "                      include_top=False,\n",
    "                      input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "classifier_model = eff_model.output\n",
    "classifier_model = GlobalAveragePooling2D()(classifier_model)\n",
    "classifier_model = Dense(units=4, activation=\"softmax\")(classifier_model)\n",
    "classifier_model = tf.keras.Model(inputs= eff_model.input, outputs= classifier_model)\n",
    "\n",
    "PRE_TRAINED_MODEL = \"EfficientNetB0\"\n",
    "OPTIMIZER = \"NAdam\"\n",
    "LOSS = \"categorical_hinge\"\n",
    "MODEL_NAME = PRE_TRAINED_MODEL + \"_\" + OPTIMIZER + \"_\" + LOSS + \"_\" + str(EPOCHS)\n",
    "\n",
    "log_dir = \"/content/drive/MyDrive/LIFPROJET/Classification/logs/fit/\" + \"_\" + MODEL_NAME\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "classifier_model.compile(optimizer=keras.optimizers.Nadam(learning_rate=0.0001),\n",
    "              loss = LOSS,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "classifier_model.fit(train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                     validation_data = (X_val,y_val),\n",
    "                     epochs = EPOCHS,\n",
    "                     verbose = 0,\n",
    "                     callbacks=[tensorboard_callback])\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------\n",
    "#--------------------------------------------------------------\n",
    "#--------------------------------------------------------------\n",
    "eff_model = EfficientNetB0(weights='imagenet', # Load weights pre-trained on ImageNet.\n",
    "                      include_top=False,\n",
    "                      input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "classifier_model = eff_model.output\n",
    "classifier_model = GlobalAveragePooling2D()(classifier_model)\n",
    "classifier_model = Dense(units=4, activation=\"softmax\")(classifier_model)\n",
    "classifier_model = tf.keras.Model(inputs= eff_model.input, outputs= classifier_model)\n",
    "\n",
    "PRE_TRAINED_MODEL = \"EfficientNetB0\"\n",
    "OPTIMIZER = \"SGD\"\n",
    "LOSS = \"categorical_crossentropy\"\n",
    "MODEL_NAME = PRE_TRAINED_MODEL + \"_\" + OPTIMIZER + \"_\" + LOSS + \"_\" + str(EPOCHS)\n",
    "\n",
    "log_dir = \"/content/drive/MyDrive/LIFPROJET/Classification/logs/fit/\" + \"_\" + MODEL_NAME\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "classifier_model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.0001),\n",
    "              loss = LOSS,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "classifier_model.fit(train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                     validation_data = (X_val,y_val),\n",
    "                     epochs = EPOCHS,\n",
    "                     verbose = 0,\n",
    "                     callbacks=[tensorboard_callback])\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "eff_model = EfficientNetB0(weights='imagenet', # Load weights pre-trained on ImageNet.\n",
    "                      include_top=False,\n",
    "                      input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "classifier_model = eff_model.output\n",
    "classifier_model = GlobalAveragePooling2D()(classifier_model)\n",
    "classifier_model = Dense(units=4, activation=\"softmax\")(classifier_model)\n",
    "classifier_model = tf.keras.Model(inputs= eff_model.input, outputs= classifier_model)\n",
    "\n",
    "PRE_TRAINED_MODEL = \"EfficientNetB0\"\n",
    "OPTIMIZER = \"SGD\"\n",
    "LOSS = \"kl_divergence\"\n",
    "MODEL_NAME = PRE_TRAINED_MODEL + \"_\" + OPTIMIZER + \"_\" + LOSS + \"_\" + str(EPOCHS)\n",
    "\n",
    "log_dir = \"/content/drive/MyDrive/LIFPROJET/Classification/logs/fit/\" + \"_\" + MODEL_NAME\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "classifier_model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.0001),\n",
    "              loss = LOSS,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "classifier_model.fit(train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                     validation_data = (X_val,y_val),\n",
    "                     epochs = EPOCHS,\n",
    "                     verbose = 0,\n",
    "                     callbacks=[tensorboard_callback])\n",
    "#--------------------------------------------------------------\n",
    "eff_model = EfficientNetB0(weights='imagenet', # Load weights pre-trained on ImageNet.\n",
    "                      include_top=False,\n",
    "                      input_shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "classifier_model = eff_model.output\n",
    "classifier_model = GlobalAveragePooling2D()(classifier_model)\n",
    "classifier_model = Dense(units=4, activation=\"softmax\")(classifier_model)\n",
    "classifier_model = tf.keras.Model(inputs= eff_model.input, outputs= classifier_model)\n",
    "\n",
    "PRE_TRAINED_MODEL = \"EfficientNetB0\"\n",
    "OPTIMIZER = \"SGD\"\n",
    "LOSS = \"categorical_hinge\"\n",
    "MODEL_NAME = PRE_TRAINED_MODEL + \"_\" + OPTIMIZER + \"_\" + LOSS + \"_\" + str(EPOCHS)\n",
    "\n",
    "log_dir = \"/content/drive/MyDrive/LIFPROJET/Classification/logs/fit/\" + \"_\" + MODEL_NAME\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "classifier_model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.0001),\n",
    "              loss = LOSS,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "classifier_model.fit(train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                     validation_data = (X_val,y_val),\n",
    "                     epochs = EPOCHS,\n",
    "                     verbose = 0,\n",
    "                     callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XN5tSyWLiB14",
   "metadata": {
    "id": "XN5tSyWLiB14"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
